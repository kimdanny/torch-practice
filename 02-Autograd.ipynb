{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "accompanied-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "diagnostic-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-nicholas",
   "metadata": {},
   "source": [
    "## Forward and Backward pass without autograd (manually)\n",
    "\n",
    "Example derived from: https://github.com/jcjohnson/pytorch-examples#pytorch-autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "abstract-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "informal-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "european-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random input and output data\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "\n",
    "# Random init of weights\n",
    "w1 = torch.randn(D_in, H, device=device)\n",
    "w2 = torch.randn(H, D_out, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "occupational-pharmaceutical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 43415424.0\n",
      "1 44696848.0\n",
      "2 43684180.0\n",
      "3 33445164.0\n",
      "4 18966750.0\n",
      "5 8710072.0\n",
      "6 4064412.25\n",
      "7 2290609.0\n",
      "8 1566268.5\n",
      "9 1199763.25\n",
      "10 968629.5\n",
      "11 801704.6875\n",
      "12 672338.125\n",
      "13 569214.8125\n",
      "14 485309.5\n",
      "15 416119.875\n",
      "16 358731.25\n",
      "17 310751.9375\n",
      "18 270388.8125\n",
      "19 236253.890625\n",
      "20 207237.0625\n",
      "21 182534.671875\n",
      "22 161286.453125\n",
      "23 142934.734375\n",
      "24 127015.734375\n",
      "25 113161.7578125\n",
      "26 101051.0078125\n",
      "27 90427.078125\n",
      "28 81089.28125\n",
      "29 72849.84375\n",
      "30 65573.0859375\n",
      "31 59129.8125\n",
      "32 53400.8828125\n",
      "33 48296.6015625\n",
      "34 43737.6875\n",
      "35 39663.74609375\n",
      "36 36012.859375\n",
      "37 32736.626953125\n",
      "38 29790.51171875\n",
      "39 27138.73828125\n",
      "40 24750.560546875\n",
      "41 22593.486328125\n",
      "42 20643.345703125\n",
      "43 18878.994140625\n",
      "44 17278.8984375\n",
      "45 15827.1474609375\n",
      "46 14508.4892578125\n",
      "47 13309.392578125\n",
      "48 12217.7314453125\n",
      "49 11222.955078125\n",
      "50 10315.6689453125\n",
      "51 9487.958984375\n",
      "52 8732.1689453125\n",
      "53 8042.54833984375\n",
      "54 7411.3671875\n",
      "55 6833.11279296875\n",
      "56 6303.33154296875\n",
      "57 5817.6904296875\n",
      "58 5372.22509765625\n",
      "59 4963.30517578125\n",
      "60 4587.53271484375\n",
      "61 4242.27685546875\n",
      "62 3924.71044921875\n",
      "63 3632.486572265625\n",
      "64 3363.517333984375\n",
      "65 3115.66845703125\n",
      "66 2887.31005859375\n",
      "67 2676.739990234375\n",
      "68 2482.470703125\n",
      "69 2303.231689453125\n",
      "70 2137.859375\n",
      "71 1985.111572265625\n",
      "72 1843.936767578125\n",
      "73 1713.450439453125\n",
      "74 1592.7545166015625\n",
      "75 1481.1885986328125\n",
      "76 1377.947021484375\n",
      "77 1282.35693359375\n",
      "78 1193.7515869140625\n",
      "79 1111.63818359375\n",
      "80 1035.5294189453125\n",
      "81 964.9197387695312\n",
      "82 899.3758544921875\n",
      "83 838.5428466796875\n",
      "84 782.0758056640625\n",
      "85 729.6151123046875\n",
      "86 680.8707885742188\n",
      "87 635.5489501953125\n",
      "88 593.4110107421875\n",
      "89 554.21923828125\n",
      "90 517.75439453125\n",
      "91 483.81298828125\n",
      "92 452.2154541015625\n",
      "93 422.8099365234375\n",
      "94 395.3942565917969\n",
      "95 369.84674072265625\n",
      "96 346.0328674316406\n",
      "97 323.83599853515625\n",
      "98 303.13372802734375\n",
      "99 283.8177490234375\n",
      "100 265.7954406738281\n",
      "101 248.9683380126953\n",
      "102 233.26231384277344\n",
      "103 218.60025024414062\n",
      "104 204.90267944335938\n",
      "105 192.10301208496094\n",
      "106 180.13731384277344\n",
      "107 168.9537353515625\n",
      "108 158.49563598632812\n",
      "109 148.71580505371094\n",
      "110 139.5640869140625\n",
      "111 131.00485229492188\n",
      "112 122.99302673339844\n",
      "113 115.493408203125\n",
      "114 108.47055053710938\n",
      "115 101.89388275146484\n",
      "116 95.73390197753906\n",
      "117 89.96172332763672\n",
      "118 84.55265808105469\n",
      "119 79.47979736328125\n",
      "120 74.72746276855469\n",
      "121 70.27068328857422\n",
      "122 66.08987426757812\n",
      "123 62.168975830078125\n",
      "124 58.488914489746094\n",
      "125 55.03449630737305\n",
      "126 51.795841217041016\n",
      "127 48.75247573852539\n",
      "128 45.89561462402344\n",
      "129 43.212093353271484\n",
      "130 40.691993713378906\n",
      "131 38.32554626464844\n",
      "132 36.10173797607422\n",
      "133 34.01107406616211\n",
      "134 32.04631042480469\n",
      "135 30.19831657409668\n",
      "136 28.46202850341797\n",
      "137 26.828828811645508\n",
      "138 25.29282569885254\n",
      "139 23.847482681274414\n",
      "140 22.48734474182129\n",
      "141 21.20895767211914\n",
      "142 20.004621505737305\n",
      "143 18.871116638183594\n",
      "144 17.804569244384766\n",
      "145 16.800048828125\n",
      "146 15.85400390625\n",
      "147 14.962793350219727\n",
      "148 14.123520851135254\n",
      "149 13.333536148071289\n",
      "150 12.588390350341797\n",
      "151 11.886964797973633\n",
      "152 11.22481632232666\n",
      "153 10.601511001586914\n",
      "154 10.013476371765137\n",
      "155 9.459708213806152\n",
      "156 8.937344551086426\n",
      "157 8.44412899017334\n",
      "158 7.979334831237793\n",
      "159 7.5409321784973145\n",
      "160 7.1273651123046875\n",
      "161 6.737279891967773\n",
      "162 6.368941307067871\n",
      "163 6.021684646606445\n",
      "164 5.692924499511719\n",
      "165 5.383893013000488\n",
      "166 5.091262340545654\n",
      "167 4.815418720245361\n",
      "168 4.55483341217041\n",
      "169 4.308650016784668\n",
      "170 4.076155662536621\n",
      "171 3.8567233085632324\n",
      "172 3.649221897125244\n",
      "173 3.453098773956299\n",
      "174 3.268481969833374\n",
      "175 3.0929412841796875\n",
      "176 2.927748680114746\n",
      "177 2.7716073989868164\n",
      "178 2.6237001419067383\n",
      "179 2.484163999557495\n",
      "180 2.352044105529785\n",
      "181 2.2271649837493896\n",
      "182 2.1091268062591553\n",
      "183 1.9975849390029907\n",
      "184 1.8921928405761719\n",
      "185 1.7923463582992554\n",
      "186 1.6976525783538818\n",
      "187 1.6084064245224\n",
      "188 1.523837924003601\n",
      "189 1.443783164024353\n",
      "190 1.3681621551513672\n",
      "191 1.2965253591537476\n",
      "192 1.228678822517395\n",
      "193 1.1644926071166992\n",
      "194 1.103729486465454\n",
      "195 1.046279788017273\n",
      "196 0.9917606711387634\n",
      "197 0.9402688145637512\n",
      "198 0.891571581363678\n",
      "199 0.8451684713363647\n",
      "200 0.8014169335365295\n",
      "201 0.7599999904632568\n",
      "202 0.7206903696060181\n",
      "203 0.6835877895355225\n",
      "204 0.6482522487640381\n",
      "205 0.6149307489395142\n",
      "206 0.583259642124176\n",
      "207 0.5533674955368042\n",
      "208 0.5249274969100952\n",
      "209 0.4980616271495819\n",
      "210 0.47252005338668823\n",
      "211 0.4483678340911865\n",
      "212 0.42549633979797363\n",
      "213 0.40374791622161865\n",
      "214 0.3831813931465149\n",
      "215 0.3636537492275238\n",
      "216 0.3451055586338043\n",
      "217 0.3276102542877197\n",
      "218 0.31093043088912964\n",
      "219 0.2951565980911255\n",
      "220 0.28022119402885437\n",
      "221 0.26602703332901\n",
      "222 0.25263330340385437\n",
      "223 0.23983100056648254\n",
      "224 0.2277045100927353\n",
      "225 0.2162148654460907\n",
      "226 0.2052822709083557\n",
      "227 0.194915309548378\n",
      "228 0.18516632914543152\n",
      "229 0.17590051889419556\n",
      "230 0.16705098748207092\n",
      "231 0.15864241123199463\n",
      "232 0.15068389475345612\n",
      "233 0.14317618310451508\n",
      "234 0.1360313892364502\n",
      "235 0.12921473383903503\n",
      "236 0.12275499105453491\n",
      "237 0.11663509905338287\n",
      "238 0.11079458147287369\n",
      "239 0.10527340322732925\n",
      "240 0.10008122026920319\n",
      "241 0.09509825706481934\n",
      "242 0.09037043899297714\n",
      "243 0.0858473926782608\n",
      "244 0.08158589899539948\n",
      "245 0.07758626341819763\n",
      "246 0.07374333590269089\n",
      "247 0.07010146230459213\n",
      "248 0.06660985201597214\n",
      "249 0.06331704556941986\n",
      "250 0.060224395245313644\n",
      "251 0.05723836272954941\n",
      "252 0.054428860545158386\n",
      "253 0.05174336954951286\n",
      "254 0.049186453223228455\n",
      "255 0.04675963893532753\n",
      "256 0.04446698725223541\n",
      "257 0.04230119660496712\n",
      "258 0.04022424295544624\n",
      "259 0.03827008605003357\n",
      "260 0.036387622356414795\n",
      "261 0.0346062034368515\n",
      "262 0.03291476145386696\n",
      "263 0.03130243718624115\n",
      "264 0.02979338727891445\n",
      "265 0.028350241482257843\n",
      "266 0.026975063607096672\n",
      "267 0.025674346834421158\n",
      "268 0.024421466514468193\n",
      "269 0.023217588663101196\n",
      "270 0.022096727043390274\n",
      "271 0.021030209958553314\n",
      "272 0.02001316286623478\n",
      "273 0.019050195813179016\n",
      "274 0.018140019848942757\n",
      "275 0.017266908660531044\n",
      "276 0.01643230766057968\n",
      "277 0.015643449500203133\n",
      "278 0.014896901324391365\n",
      "279 0.0141828628256917\n",
      "280 0.01349812000989914\n",
      "281 0.012854723259806633\n",
      "282 0.012252301909029484\n",
      "283 0.01166391558945179\n",
      "284 0.011108983308076859\n",
      "285 0.010583372786641121\n",
      "286 0.010075129568576813\n",
      "287 0.009598715230822563\n",
      "288 0.009160940535366535\n",
      "289 0.008730086497962475\n",
      "290 0.00832636933773756\n",
      "291 0.007930244319140911\n",
      "292 0.007555525749921799\n",
      "293 0.007205992005765438\n",
      "294 0.0068759433925151825\n",
      "295 0.006559981498867273\n",
      "296 0.006253516301512718\n",
      "297 0.005965227726846933\n",
      "298 0.005693675950169563\n",
      "299 0.005435219965875149\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-6\n",
    "\n",
    "for epoch in range(300):\n",
    "    # Forward Pass\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = (y_pred - y).pow(2).sum()  # scalar\n",
    "    print(epoch, loss.item())\n",
    "    \n",
    "    # Back propagation: \n",
    "    # compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    \n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h<0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "    \n",
    "    # grad update using gradient descent\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "blind-consolidation",
   "metadata": {},
   "source": [
    "## With Autograd + vanilla gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "laden-cooperative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 25942616.0\n",
      "1 20826046.0\n",
      "2 21238560.0\n",
      "3 24298532.0\n",
      "4 27461800.0\n",
      "5 27520630.0\n",
      "6 23098542.0\n",
      "7 15689217.0\n",
      "8 9032992.0\n",
      "9 4725458.5\n",
      "10 2497366.5\n",
      "11 1430850.25\n",
      "12 924970.3125\n",
      "13 668213.125\n",
      "14 523413.75\n",
      "15 430951.75\n",
      "16 365188.375\n",
      "17 314705.9375\n",
      "18 273972.0625\n",
      "19 240077.625\n",
      "20 211379.9375\n",
      "21 186838.140625\n",
      "22 165708.109375\n",
      "23 147398.984375\n",
      "24 131448.203125\n",
      "25 117494.234375\n",
      "26 105251.5625\n",
      "27 94476.8203125\n",
      "28 84960.921875\n",
      "29 76537.9375\n",
      "30 69059.5078125\n",
      "31 62410.171875\n",
      "32 56484.2734375\n",
      "33 51188.12890625\n",
      "34 46455.6015625\n",
      "35 42215.66796875\n",
      "36 38405.8359375\n",
      "37 34979.69921875\n",
      "38 31894.5703125\n",
      "39 29110.30078125\n",
      "40 26594.232421875\n",
      "41 24316.7734375\n",
      "42 22253.53125\n",
      "43 20383.240234375\n",
      "44 18684.919921875\n",
      "45 17141.2890625\n",
      "46 15736.83984375\n",
      "47 14458.1484375\n",
      "48 13292.1416015625\n",
      "49 12228.306640625\n",
      "50 11257.6259765625\n",
      "51 10371.16796875\n",
      "52 9560.66796875\n",
      "53 8818.88671875\n",
      "54 8139.2236328125\n",
      "55 7515.86865234375\n",
      "56 6944.18505859375\n",
      "57 6419.4326171875\n",
      "58 5937.2744140625\n",
      "59 5494.17578125\n",
      "60 5086.65283203125\n",
      "61 4711.6875\n",
      "62 4366.24658203125\n",
      "63 4048.51611328125\n",
      "64 3756.107421875\n",
      "65 3486.38623046875\n",
      "66 3237.45361328125\n",
      "67 3007.64990234375\n",
      "68 2795.42529296875\n",
      "69 2599.15185546875\n",
      "70 2417.54296875\n",
      "71 2249.4833984375\n",
      "72 2093.933349609375\n",
      "73 1949.855712890625\n",
      "74 1816.3770751953125\n",
      "75 1692.614013671875\n",
      "76 1577.8533935546875\n",
      "77 1471.80615234375\n",
      "78 1373.4193115234375\n",
      "79 1282.05029296875\n",
      "80 1197.17431640625\n",
      "81 1118.290771484375\n",
      "82 1044.960205078125\n",
      "83 976.7587280273438\n",
      "84 913.3074340820312\n",
      "85 854.253173828125\n",
      "86 799.25537109375\n",
      "87 748.024169921875\n",
      "88 700.2911376953125\n",
      "89 655.7902221679688\n",
      "90 614.2935180664062\n",
      "91 575.5859985351562\n",
      "92 539.4696655273438\n",
      "93 505.7569274902344\n",
      "94 474.2779846191406\n",
      "95 444.87957763671875\n",
      "96 417.4093933105469\n",
      "97 391.7268371582031\n",
      "98 367.74560546875\n",
      "99 345.3154602050781\n",
      "100 324.3386535644531\n",
      "101 304.7118835449219\n",
      "102 286.3387451171875\n",
      "103 269.1370544433594\n",
      "104 253.02517700195312\n",
      "105 237.9351806640625\n",
      "106 223.80191040039062\n",
      "107 210.549072265625\n",
      "108 198.12234497070312\n",
      "109 186.472900390625\n",
      "110 175.54254150390625\n",
      "111 165.2851104736328\n",
      "112 155.65989685058594\n",
      "113 146.62693786621094\n",
      "114 138.14419555664062\n",
      "115 130.1764678955078\n",
      "116 122.69471740722656\n",
      "117 115.66516876220703\n",
      "118 109.05683898925781\n",
      "119 102.84527587890625\n",
      "120 97.00782775878906\n",
      "121 91.51609802246094\n",
      "122 86.34988403320312\n",
      "123 81.49073028564453\n",
      "124 76.91913604736328\n",
      "125 72.6144027709961\n",
      "126 68.56217193603516\n",
      "127 64.74628448486328\n",
      "128 61.152530670166016\n",
      "129 57.76698303222656\n",
      "130 54.579166412353516\n",
      "131 51.57391357421875\n",
      "132 48.741600036621094\n",
      "133 46.071937561035156\n",
      "134 43.55453109741211\n",
      "135 41.18109130859375\n",
      "136 38.94211959838867\n",
      "137 36.829471588134766\n",
      "138 34.836971282958984\n",
      "139 32.955413818359375\n",
      "140 31.1815242767334\n",
      "141 29.506351470947266\n",
      "142 27.924760818481445\n",
      "143 26.431678771972656\n",
      "144 25.020404815673828\n",
      "145 23.688581466674805\n",
      "146 22.429489135742188\n",
      "147 21.240224838256836\n",
      "148 20.116138458251953\n",
      "149 19.053695678710938\n",
      "150 18.049768447875977\n",
      "151 17.100788116455078\n",
      "152 16.202707290649414\n",
      "153 15.353536605834961\n",
      "154 14.550592422485352\n",
      "155 13.791187286376953\n",
      "156 13.073287010192871\n",
      "157 12.393409729003906\n",
      "158 11.750130653381348\n",
      "159 11.141566276550293\n",
      "160 10.565659523010254\n",
      "161 10.019988059997559\n",
      "162 9.503400802612305\n",
      "163 9.014482498168945\n",
      "164 8.551600456237793\n",
      "165 8.113142013549805\n",
      "166 7.697803974151611\n",
      "167 7.304401397705078\n",
      "168 6.931577205657959\n",
      "169 6.578293800354004\n",
      "170 6.2436981201171875\n",
      "171 5.9263434410095215\n",
      "172 5.625945091247559\n",
      "173 5.341071128845215\n",
      "174 5.070941925048828\n",
      "175 4.814844608306885\n",
      "176 4.571934223175049\n",
      "177 4.341825008392334\n",
      "178 4.123412609100342\n",
      "179 3.916170597076416\n",
      "180 3.7197914123535156\n",
      "181 3.5336380004882812\n",
      "182 3.3566880226135254\n",
      "183 3.188933849334717\n",
      "184 3.029863119125366\n",
      "185 2.878807544708252\n",
      "186 2.7355802059173584\n",
      "187 2.599594831466675\n",
      "188 2.4705121517181396\n",
      "189 2.3480160236358643\n",
      "190 2.2316386699676514\n",
      "191 2.1212754249572754\n",
      "192 2.0164928436279297\n",
      "193 1.9167689085006714\n",
      "194 1.822217583656311\n",
      "195 1.7325069904327393\n",
      "196 1.6472653150558472\n",
      "197 1.566203236579895\n",
      "198 1.489337682723999\n",
      "199 1.4163134098052979\n",
      "200 1.3467308282852173\n",
      "201 1.281026840209961\n",
      "202 1.218302607536316\n",
      "203 1.1587506532669067\n",
      "204 1.1020327806472778\n",
      "205 1.048343539237976\n",
      "206 0.9972343444824219\n",
      "207 0.9486919641494751\n",
      "208 0.9026497006416321\n",
      "209 0.8586453199386597\n",
      "210 0.816966712474823\n",
      "211 0.7774587273597717\n",
      "212 0.7397652864456177\n",
      "213 0.7038860321044922\n",
      "214 0.669808566570282\n",
      "215 0.6374770402908325\n",
      "216 0.6066079139709473\n",
      "217 0.577322781085968\n",
      "218 0.54948890209198\n",
      "219 0.5229593515396118\n",
      "220 0.4978405833244324\n",
      "221 0.4738529324531555\n",
      "222 0.4511038362979889\n",
      "223 0.429467111825943\n",
      "224 0.4088265895843506\n",
      "225 0.38920724391937256\n",
      "226 0.3705310523509979\n",
      "227 0.35281306505203247\n",
      "228 0.33587998151779175\n",
      "229 0.31986695528030396\n",
      "230 0.3045331835746765\n",
      "231 0.289994478225708\n",
      "232 0.2761073112487793\n",
      "233 0.26295191049575806\n",
      "234 0.25042155385017395\n",
      "235 0.23849719762802124\n",
      "236 0.2271004319190979\n",
      "237 0.21634306013584137\n",
      "238 0.20603488385677338\n",
      "239 0.1962323933839798\n",
      "240 0.18690676987171173\n",
      "241 0.17802825570106506\n",
      "242 0.1695612370967865\n",
      "243 0.16153985261917114\n",
      "244 0.1538815200328827\n",
      "245 0.14659357070922852\n",
      "246 0.13965845108032227\n",
      "247 0.13308094441890717\n",
      "248 0.1268043965101242\n",
      "249 0.12080013751983643\n",
      "250 0.1151164174079895\n",
      "251 0.1096472442150116\n",
      "252 0.10448578000068665\n",
      "253 0.09954792261123657\n",
      "254 0.09485328197479248\n",
      "255 0.09039079397916794\n",
      "256 0.08612018078565598\n",
      "257 0.08206554502248764\n",
      "258 0.07821135967969894\n",
      "259 0.07453175634145737\n",
      "260 0.07102581858634949\n",
      "261 0.06769803911447525\n",
      "262 0.06452002376317978\n",
      "263 0.06151480972766876\n",
      "264 0.0586385503411293\n",
      "265 0.055892039090394974\n",
      "266 0.053265079855918884\n",
      "267 0.05078187584877014\n",
      "268 0.04839601367712021\n",
      "269 0.046131931245326996\n",
      "270 0.04397236555814743\n",
      "271 0.0419219434261322\n",
      "272 0.03996667265892029\n",
      "273 0.03810688853263855\n",
      "274 0.03633374720811844\n",
      "275 0.03464692085981369\n",
      "276 0.03302181139588356\n",
      "277 0.031496670097112656\n",
      "278 0.030032258480787277\n",
      "279 0.02864118479192257\n",
      "280 0.02731655165553093\n",
      "281 0.0260373055934906\n",
      "282 0.02483513578772545\n",
      "283 0.023680059239268303\n",
      "284 0.022584665566682816\n",
      "285 0.021542543545365334\n",
      "286 0.02055382914841175\n",
      "287 0.01961664855480194\n",
      "288 0.01871565543115139\n",
      "289 0.01785282976925373\n",
      "290 0.017036469653248787\n",
      "291 0.016249673441052437\n",
      "292 0.015519930981099606\n",
      "293 0.014801968820393085\n",
      "294 0.01412374060600996\n",
      "295 0.013489357195794582\n",
      "296 0.012863713316619396\n",
      "297 0.01227655727416277\n",
      "298 0.011723015457391739\n",
      "299 0.011187465861439705\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "w1 = torch.randn(D_in, H, device=device, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, requires_grad=True)\n",
    "\n",
    "lr = 1e-6\n",
    "for epoch in range(300):\n",
    "    # Forward Pass\n",
    "    # Forward pass: compute predicted y using operations on Tensors. Since w1 and\n",
    "    # w2 have requires_grad=True, operations involving these Tensors will cause\n",
    "    # PyTorch to build a computational graph, allowing automatic computation of\n",
    "    # gradients. Since we are no longer implementing the backward pass by hand we\n",
    "    # don't need to keep references to intermediate values.\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(epoch, loss.item())\n",
    "    \n",
    "    # USE AUTOGRAD\n",
    "    # to compute backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    # After this call w1.grad and w2.grad will be Tensors holding the gradient\n",
    "    # of the loss with respect to w1 and w2 respectively.\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update weights using gradient descent. For this step we just want to mutate\n",
    "    # the values of w1 and w2 in-place; we don't want to build up a computational\n",
    "    # graph for the update steps, so we use the torch.no_grad() context manager\n",
    "    # to prevent PyTorch from building a computational graph for the updates\n",
    "    with torch.no_grad():\n",
    "        w1 -= lr * w1.grad\n",
    "        w2 -= lr * w2.grad\n",
    "        \n",
    "        # Manually zero the gradients after running the backward pass\n",
    "        # https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-handbook",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "worse-investing",
   "metadata": {},
   "source": [
    "## With Autograd + Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "comparative-hygiene",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 35422672.0\n",
      "1 31244452.0\n",
      "2 28708928.0\n",
      "3 24129812.0\n",
      "4 17419576.0\n",
      "5 10978274.0\n",
      "6 6379350.0\n",
      "7 3729778.0\n",
      "8 2318253.5\n",
      "9 1574131.125\n",
      "10 1156691.0\n",
      "11 901313.375\n",
      "12 729261.875\n",
      "13 603939.6875\n",
      "14 507661.5625\n",
      "15 430981.75\n",
      "16 368564.375\n",
      "17 317045.3125\n",
      "18 274153.0625\n",
      "19 238073.703125\n",
      "20 207548.453125\n",
      "21 181526.75\n",
      "22 159270.125\n",
      "23 140161.234375\n",
      "24 123703.1484375\n",
      "25 109522.09375\n",
      "26 97207.453125\n",
      "27 86468.0\n",
      "28 77089.53125\n",
      "29 68868.734375\n",
      "30 61637.90234375\n",
      "31 55276.75390625\n",
      "32 49662.20703125\n",
      "33 44685.2890625\n",
      "34 40267.234375\n",
      "35 36335.375\n",
      "36 32832.31640625\n",
      "37 29705.0625\n",
      "38 26908.01171875\n",
      "39 24408.0390625\n",
      "40 22169.15234375\n",
      "41 20155.203125\n",
      "42 18342.9375\n",
      "43 16709.94140625\n",
      "44 15236.373046875\n",
      "45 13905.875\n",
      "46 12702.7001953125\n",
      "47 11613.4140625\n",
      "48 10625.9501953125\n",
      "49 9729.59765625\n",
      "50 8915.24609375\n",
      "51 8174.51171875\n",
      "52 7500.447265625\n",
      "53 6886.6396484375\n",
      "54 6327.103515625\n",
      "55 5816.962890625\n",
      "56 5350.97998046875\n",
      "57 4925.408203125\n",
      "58 4536.0712890625\n",
      "59 4179.69970703125\n",
      "60 3853.388671875\n",
      "61 3554.298095703125\n",
      "62 3280.05615234375\n",
      "63 3029.184326171875\n",
      "64 2798.77294921875\n",
      "65 2587.1201171875\n",
      "66 2392.4931640625\n",
      "67 2213.429931640625\n",
      "68 2048.6630859375\n",
      "69 1896.947265625\n",
      "70 1757.1688232421875\n",
      "71 1628.365478515625\n",
      "72 1509.6343994140625\n",
      "73 1400.122802734375\n",
      "74 1298.9559326171875\n",
      "75 1205.51123046875\n",
      "76 1119.19970703125\n",
      "77 1039.4202880859375\n",
      "78 965.6365356445312\n",
      "79 897.4200439453125\n",
      "80 834.2886962890625\n",
      "81 775.818603515625\n",
      "82 721.6614379882812\n",
      "83 671.4833984375\n",
      "84 624.9764404296875\n",
      "85 581.8729248046875\n",
      "86 541.9012451171875\n",
      "87 504.8058166503906\n",
      "88 470.3739929199219\n",
      "89 438.3994140625\n",
      "90 408.70556640625\n",
      "91 381.1441345214844\n",
      "92 355.5218200683594\n",
      "93 331.699462890625\n",
      "94 309.5452880859375\n",
      "95 288.94122314453125\n",
      "96 269.7921142578125\n",
      "97 251.95266723632812\n",
      "98 235.33969116210938\n",
      "99 219.9248046875\n",
      "100 205.5927734375\n",
      "101 192.23556518554688\n",
      "102 179.78216552734375\n",
      "103 168.1758270263672\n",
      "104 157.35763549804688\n",
      "105 147.2677001953125\n",
      "106 137.84815979003906\n",
      "107 129.05908203125\n",
      "108 120.8570556640625\n",
      "109 113.198974609375\n",
      "110 106.04542541503906\n",
      "111 99.36271667480469\n",
      "112 93.12205505371094\n",
      "113 87.28768920898438\n",
      "114 81.84134674072266\n",
      "115 76.76622772216797\n",
      "116 72.01628112792969\n",
      "117 67.57503509521484\n",
      "118 63.41920852661133\n",
      "119 59.52924346923828\n",
      "120 55.888545989990234\n",
      "121 52.47655487060547\n",
      "122 49.28282928466797\n",
      "123 46.29004669189453\n",
      "124 43.48506164550781\n",
      "125 40.85761642456055\n",
      "126 38.39529800415039\n",
      "127 36.085845947265625\n",
      "128 33.92079162597656\n",
      "129 31.890270233154297\n",
      "130 29.986663818359375\n",
      "131 28.200214385986328\n",
      "132 26.523372650146484\n",
      "133 24.94974136352539\n",
      "134 23.472545623779297\n",
      "135 22.086334228515625\n",
      "136 20.783855438232422\n",
      "137 19.560649871826172\n",
      "138 18.412004470825195\n",
      "139 17.332948684692383\n",
      "140 16.319164276123047\n",
      "141 15.366862297058105\n",
      "142 14.471652030944824\n",
      "143 13.630276679992676\n",
      "144 12.838669776916504\n",
      "145 12.09505558013916\n",
      "146 11.395133972167969\n",
      "147 10.736989974975586\n",
      "148 10.118398666381836\n",
      "149 9.536145210266113\n",
      "150 8.988105773925781\n",
      "151 8.47244644165039\n",
      "152 7.987603187561035\n",
      "153 7.531063079833984\n",
      "154 7.101120471954346\n",
      "155 6.696281433105469\n",
      "156 6.314840793609619\n",
      "157 5.956079483032227\n",
      "158 5.618070125579834\n",
      "159 5.299625396728516\n",
      "160 4.99997615814209\n",
      "161 4.717270851135254\n",
      "162 4.451322555541992\n",
      "163 4.200795650482178\n",
      "164 3.96417236328125\n",
      "165 3.7414302825927734\n",
      "166 3.5311920642852783\n",
      "167 3.333508253097534\n",
      "168 3.1468517780303955\n",
      "169 2.970731735229492\n",
      "170 2.8047828674316406\n",
      "171 2.648343086242676\n",
      "172 2.5008559226989746\n",
      "173 2.3616697788238525\n",
      "174 2.2303740978240967\n",
      "175 2.1065917015075684\n",
      "176 1.9896814823150635\n",
      "177 1.8794105052947998\n",
      "178 1.7754948139190674\n",
      "179 1.677259922027588\n",
      "180 1.584583044052124\n",
      "181 1.497150182723999\n",
      "182 1.4145798683166504\n",
      "183 1.3368147611618042\n",
      "184 1.2630059719085693\n",
      "185 1.19375741481781\n",
      "186 1.128179907798767\n",
      "187 1.066266655921936\n",
      "188 1.0079182386398315\n",
      "189 0.9526470303535461\n",
      "190 0.9004982709884644\n",
      "191 0.8512877821922302\n",
      "192 0.8048546314239502\n",
      "193 0.7609100937843323\n",
      "194 0.71953946352005\n",
      "195 0.6803787350654602\n",
      "196 0.6432311534881592\n",
      "197 0.608267068862915\n",
      "198 0.5752527713775635\n",
      "199 0.5439800024032593\n",
      "200 0.5144890546798706\n",
      "201 0.48649314045906067\n",
      "202 0.46020859479904175\n",
      "203 0.43528324365615845\n",
      "204 0.411772757768631\n",
      "205 0.38953855633735657\n",
      "206 0.3685097098350525\n",
      "207 0.34858185052871704\n",
      "208 0.3298320770263672\n",
      "209 0.31195729970932007\n",
      "210 0.2951834499835968\n",
      "211 0.27931922674179077\n",
      "212 0.26427963376045227\n",
      "213 0.2500445544719696\n",
      "214 0.23665842413902283\n",
      "215 0.22395670413970947\n",
      "216 0.21191582083702087\n",
      "217 0.20056314766407013\n",
      "218 0.18981952965259552\n",
      "219 0.17966163158416748\n",
      "220 0.1700044721364975\n",
      "221 0.160908043384552\n",
      "222 0.15232914686203003\n",
      "223 0.14416515827178955\n",
      "224 0.1364733874797821\n",
      "225 0.12918990850448608\n",
      "226 0.12230200320482254\n",
      "227 0.11578532308340073\n",
      "228 0.10961084067821503\n",
      "229 0.10378409922122955\n",
      "230 0.09824297577142715\n",
      "231 0.09304046630859375\n",
      "232 0.08809684216976166\n",
      "233 0.08340708911418915\n",
      "234 0.0789940133690834\n",
      "235 0.07483695447444916\n",
      "236 0.07085020840167999\n",
      "237 0.0670914277434349\n",
      "238 0.0635111853480339\n",
      "239 0.060132961720228195\n",
      "240 0.05695579946041107\n",
      "241 0.05396801233291626\n",
      "242 0.0510970838367939\n",
      "243 0.04839254915714264\n",
      "244 0.04586200788617134\n",
      "245 0.043434690684080124\n",
      "246 0.041137050837278366\n",
      "247 0.03897716850042343\n",
      "248 0.03690814971923828\n",
      "249 0.034980565309524536\n",
      "250 0.03313364088535309\n",
      "251 0.03140299394726753\n",
      "252 0.02975725568830967\n",
      "253 0.02819743938744068\n",
      "254 0.026726078242063522\n",
      "255 0.025321369990706444\n",
      "256 0.02400027960538864\n",
      "257 0.022751592099666595\n",
      "258 0.021537907421588898\n",
      "259 0.02042723447084427\n",
      "260 0.019354527816176414\n",
      "261 0.018351519480347633\n",
      "262 0.017406197264790535\n",
      "263 0.016483094543218613\n",
      "264 0.01563800498843193\n",
      "265 0.014830924570560455\n",
      "266 0.014064567163586617\n",
      "267 0.013332895934581757\n",
      "268 0.012648455798625946\n",
      "269 0.011996780522167683\n",
      "270 0.011374043300747871\n",
      "271 0.01079344842582941\n",
      "272 0.01023661345243454\n",
      "273 0.009718196466565132\n",
      "274 0.009222905151546001\n",
      "275 0.008749456144869328\n",
      "276 0.008306184783577919\n",
      "277 0.007884194143116474\n",
      "278 0.007482795510441065\n",
      "279 0.007105267606675625\n",
      "280 0.006747554987668991\n",
      "281 0.006410559639334679\n",
      "282 0.006089567206799984\n",
      "283 0.005783423315733671\n",
      "284 0.005496689584106207\n",
      "285 0.005222256761044264\n",
      "286 0.004965680651366711\n",
      "287 0.004725780338048935\n",
      "288 0.004492063075304031\n",
      "289 0.004274670500308275\n",
      "290 0.004069291986525059\n",
      "291 0.003870331449434161\n",
      "292 0.0036821365356445312\n",
      "293 0.0035043940879404545\n",
      "294 0.003340735100209713\n",
      "295 0.003178774379193783\n",
      "296 0.0030283071100711823\n",
      "297 0.0028879838064312935\n",
      "298 0.0027567327488213778\n",
      "299 0.0026256442070007324\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "w1 = torch.randn(D_in, H, device=device, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, requires_grad=True)\n",
    "\n",
    "lr = 1e-6\n",
    "\n",
    "optimizer = torch.optim.SGD([w1, w2], lr=lr)\n",
    "\n",
    "for epoch in range(300):\n",
    "    # Forward Pass\n",
    "    # Forward pass: compute predicted y using operations on Tensors. Since w1 and\n",
    "    # w2 have requires_grad=True, operations involving these Tensors will cause\n",
    "    # PyTorch to build a computational graph, allowing automatic computation of\n",
    "    # gradients. Since we are no longer implementing the backward pass by hand we\n",
    "    # don't need to keep references to intermediate values.\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(epoch, loss.item())\n",
    "    \n",
    "    # USE AUTOGRAD\n",
    "    # to compute backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    # After this call w1.grad and w2.grad will be Tensors holding the gradient\n",
    "    # of the loss with respect to w1 and w2 respectively.\n",
    "    loss.backward()\n",
    "    \n",
    "    # We are not doing this here\n",
    "    # Using optimizer to step towards gradient descent and zeroing out grad\n",
    "#     with torch.no_grad():\n",
    "#         w1 -= lr * w1.grad\n",
    "#         w2 -= lr * w2.grad\n",
    "        \n",
    "#         w1.grad.zero_()\n",
    "#         w2.grad.zero_()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-utility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-lighter",
   "metadata": {},
   "source": [
    "## With Autograd + Optimizer + nn.Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cordless-overall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 31530432.0\n",
      "1 27427456.0\n",
      "2 25455544.0\n",
      "3 22159162.0\n",
      "4 17361252.0\n",
      "5 11939529.0\n",
      "6 7576283.0\n",
      "7 4628189.0\n",
      "8 2899822.5\n",
      "9 1918916.75\n",
      "10 1362040.0\n",
      "11 1028755.5625\n",
      "12 816119.0625\n",
      "13 669863.8125\n",
      "14 562692.875\n",
      "15 480055.0\n",
      "16 414132.09375\n",
      "17 360321.8125\n",
      "18 315366.1875\n",
      "19 277332.28125\n",
      "20 244851.703125\n",
      "21 216940.359375\n",
      "22 192817.59375\n",
      "23 171837.0625\n",
      "24 153509.84375\n",
      "25 137438.78125\n",
      "26 123300.484375\n",
      "27 110826.3359375\n",
      "28 99813.8515625\n",
      "29 90043.796875\n",
      "30 81356.953125\n",
      "31 73628.203125\n",
      "32 66745.9765625\n",
      "33 60588.0078125\n",
      "34 55069.015625\n",
      "35 50133.65625\n",
      "36 45697.0859375\n",
      "37 41701.05078125\n",
      "38 38097.625\n",
      "39 34840.1875\n",
      "40 31892.080078125\n",
      "41 29220.615234375\n",
      "42 26797.38671875\n",
      "43 24594.669921875\n",
      "44 22592.22265625\n",
      "45 20769.8046875\n",
      "46 19111.189453125\n",
      "47 17597.154296875\n",
      "48 16214.876953125\n",
      "49 14952.4462890625\n",
      "50 13796.84375\n",
      "51 12738.6064453125\n",
      "52 11768.7392578125\n",
      "53 10879.9345703125\n",
      "54 10063.953125\n",
      "55 9314.177734375\n",
      "56 8625.0712890625\n",
      "57 7990.9541015625\n",
      "58 7406.95458984375\n",
      "59 6868.9033203125\n",
      "60 6373.40625\n",
      "61 5918.35693359375\n",
      "62 5498.38818359375\n",
      "63 5110.44580078125\n",
      "64 4751.9765625\n",
      "65 4420.97900390625\n",
      "66 4114.7255859375\n",
      "67 3831.291015625\n",
      "68 3568.817626953125\n",
      "69 3325.46337890625\n",
      "70 3099.98876953125\n",
      "71 2890.911376953125\n",
      "72 2696.892822265625\n",
      "73 2516.68701171875\n",
      "74 2349.3349609375\n",
      "75 2193.812744140625\n",
      "76 2049.1904296875\n",
      "77 1914.7015380859375\n",
      "78 1789.52197265625\n",
      "79 1672.978759765625\n",
      "80 1564.4517822265625\n",
      "81 1463.376708984375\n",
      "82 1369.1539306640625\n",
      "83 1281.3602294921875\n",
      "84 1199.47998046875\n",
      "85 1123.1378173828125\n",
      "86 1051.885009765625\n",
      "87 985.4000244140625\n",
      "88 923.309326171875\n",
      "89 865.3375244140625\n",
      "90 811.1866455078125\n",
      "91 760.6092529296875\n",
      "92 713.36279296875\n",
      "93 669.1876831054688\n",
      "94 627.8792724609375\n",
      "95 589.25\n",
      "96 553.0966186523438\n",
      "97 519.26171875\n",
      "98 487.584716796875\n",
      "99 457.9960021972656\n",
      "100 430.2925109863281\n",
      "101 404.334716796875\n",
      "102 380.0081787109375\n",
      "103 357.2088623046875\n",
      "104 335.84039306640625\n",
      "105 315.80224609375\n",
      "106 297.00640869140625\n",
      "107 279.3768310546875\n",
      "108 262.8390808105469\n",
      "109 247.31976318359375\n",
      "110 232.7482452392578\n",
      "111 219.06922912597656\n",
      "112 206.22113037109375\n",
      "113 194.15916442871094\n",
      "114 182.8267822265625\n",
      "115 172.18707275390625\n",
      "116 162.1876678466797\n",
      "117 152.79098510742188\n",
      "118 143.961669921875\n",
      "119 135.6560821533203\n",
      "120 127.84723663330078\n",
      "121 120.5018081665039\n",
      "122 113.5947494506836\n",
      "123 107.09578704833984\n",
      "124 100.98033142089844\n",
      "125 95.22599029541016\n",
      "126 89.80934143066406\n",
      "127 84.709716796875\n",
      "128 79.91047668457031\n",
      "129 75.38968658447266\n",
      "130 71.13531494140625\n",
      "131 67.12567901611328\n",
      "132 63.351558685302734\n",
      "133 59.79290771484375\n",
      "134 56.44092559814453\n",
      "135 53.2826042175293\n",
      "136 50.3045654296875\n",
      "137 47.499088287353516\n",
      "138 44.85417175292969\n",
      "139 42.36023712158203\n",
      "140 40.00844192504883\n",
      "141 37.79084014892578\n",
      "142 35.69902038574219\n",
      "143 33.72638702392578\n",
      "144 31.865678787231445\n",
      "145 30.110496520996094\n",
      "146 28.453439712524414\n",
      "147 26.890012741088867\n",
      "148 25.415061950683594\n",
      "149 24.02133560180664\n",
      "150 22.707599639892578\n",
      "151 21.46706199645996\n",
      "152 20.29587173461914\n",
      "153 19.18962860107422\n",
      "154 18.14488983154297\n",
      "155 17.157989501953125\n",
      "156 16.22686767578125\n",
      "157 15.346962928771973\n",
      "158 14.515742301940918\n",
      "159 13.730927467346191\n",
      "160 12.989130973815918\n",
      "161 12.287939071655273\n",
      "162 11.625022888183594\n",
      "163 10.999539375305176\n",
      "164 10.407280921936035\n",
      "165 9.848217964172363\n",
      "166 9.319292068481445\n",
      "167 8.819924354553223\n",
      "168 8.347280502319336\n",
      "169 7.9006547927856445\n",
      "170 7.478512763977051\n",
      "171 7.07924747467041\n",
      "172 6.701207637786865\n",
      "173 6.343985557556152\n",
      "174 6.006260871887207\n",
      "175 5.686695575714111\n",
      "176 5.3845038414001465\n",
      "177 5.0986833572387695\n",
      "178 4.828310012817383\n",
      "179 4.572165012359619\n",
      "180 4.330073356628418\n",
      "181 4.100727081298828\n",
      "182 3.884044647216797\n",
      "183 3.678739547729492\n",
      "184 3.4846558570861816\n",
      "185 3.3008599281311035\n",
      "186 3.126873016357422\n",
      "187 2.962298631668091\n",
      "188 2.806427001953125\n",
      "189 2.6586825847625732\n",
      "190 2.519191265106201\n",
      "191 2.3868374824523926\n",
      "192 2.2616772651672363\n",
      "193 2.1430420875549316\n",
      "194 2.0307888984680176\n",
      "195 1.9245758056640625\n",
      "196 1.8237982988357544\n",
      "197 1.7284761667251587\n",
      "198 1.6380568742752075\n",
      "199 1.5526295900344849\n",
      "200 1.4715394973754883\n",
      "201 1.3948737382888794\n",
      "202 1.3221186399459839\n",
      "203 1.2533595561981201\n",
      "204 1.1881028413772583\n",
      "205 1.1263229846954346\n",
      "206 1.0677568912506104\n",
      "207 1.0122898817062378\n",
      "208 0.9597266912460327\n",
      "209 0.909967303276062\n",
      "210 0.8627797961235046\n",
      "211 0.818040132522583\n",
      "212 0.7755886912345886\n",
      "213 0.7354792356491089\n",
      "214 0.6974073648452759\n",
      "215 0.6613001823425293\n",
      "216 0.6271343231201172\n",
      "217 0.5947304368019104\n",
      "218 0.564029335975647\n",
      "219 0.5348858833312988\n",
      "220 0.5072587728500366\n",
      "221 0.48108530044555664\n",
      "222 0.4563436508178711\n",
      "223 0.43277302384376526\n",
      "224 0.41054168343544006\n",
      "225 0.38943856954574585\n",
      "226 0.36932292580604553\n",
      "227 0.35037559270858765\n",
      "228 0.3323799967765808\n",
      "229 0.3152831792831421\n",
      "230 0.29908543825149536\n",
      "231 0.2837684750556946\n",
      "232 0.26919668912887573\n",
      "233 0.25538021326065063\n",
      "234 0.24228942394256592\n",
      "235 0.22987398505210876\n",
      "236 0.2180958390235901\n",
      "237 0.2069551944732666\n",
      "238 0.19634433090686798\n",
      "239 0.1862805336713791\n",
      "240 0.17675551772117615\n",
      "241 0.16773155331611633\n",
      "242 0.1591491401195526\n",
      "243 0.1510378122329712\n",
      "244 0.143347829580307\n",
      "245 0.1360349953174591\n",
      "246 0.12904147803783417\n",
      "247 0.12246185541152954\n",
      "248 0.11622855067253113\n",
      "249 0.11027680337429047\n",
      "250 0.1046806052327156\n",
      "251 0.09933304786682129\n",
      "252 0.09427545964717865\n",
      "253 0.08948913961648941\n",
      "254 0.08492568880319595\n",
      "255 0.08058073371648788\n",
      "256 0.07652786374092102\n",
      "257 0.0726303681731224\n",
      "258 0.0689234659075737\n",
      "259 0.06541609019041061\n",
      "260 0.06208840012550354\n",
      "261 0.05894521623849869\n",
      "262 0.055963657796382904\n",
      "263 0.053124137222766876\n",
      "264 0.05043407902121544\n",
      "265 0.047877535223960876\n",
      "266 0.04544453322887421\n",
      "267 0.04314962774515152\n",
      "268 0.040968216955661774\n",
      "269 0.03887881711125374\n",
      "270 0.03692233934998512\n",
      "271 0.035055942833423615\n",
      "272 0.03329183906316757\n",
      "273 0.03159843757748604\n",
      "274 0.03000965155661106\n",
      "275 0.02849740907549858\n",
      "276 0.02707267552614212\n",
      "277 0.025703418999910355\n",
      "278 0.024410052224993706\n",
      "279 0.02318495698273182\n",
      "280 0.02202819660305977\n",
      "281 0.020916882902383804\n",
      "282 0.019872115924954414\n",
      "283 0.018861323595046997\n",
      "284 0.01792145147919655\n",
      "285 0.017033014446496964\n",
      "286 0.01617586985230446\n",
      "287 0.015378092415630817\n",
      "288 0.014608854427933693\n",
      "289 0.013874937780201435\n",
      "290 0.013188589364290237\n",
      "291 0.012532604858279228\n",
      "292 0.01190905924886465\n",
      "293 0.011317289434373379\n",
      "294 0.010759594850242138\n",
      "295 0.010229414328932762\n",
      "296 0.00973222404718399\n",
      "297 0.00925455242395401\n",
      "298 0.008792598731815815\n",
      "299 0.008364196866750717\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "w1 = torch.randn(D_in, H, device=device, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, requires_grad=True)\n",
    "\n",
    "lr = 1e-6\n",
    "# Instead of manual loss implementation, Using Torch.nn.<LossFunction>\n",
    "mse_loss = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD([w1, w2], lr=lr)\n",
    "\n",
    "for epoch in range(300):\n",
    "    # Forward Pass\n",
    "    # Forward pass: compute predicted y using operations on Tensors. Since w1 and\n",
    "    # w2 have requires_grad=True, operations involving these Tensors will cause\n",
    "    # PyTorch to build a computational graph, allowing automatic computation of\n",
    "    # gradients. Since we are no longer implementing the backward pass by hand we\n",
    "    # don't need to keep references to intermediate values.\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    \n",
    "    # Compute loss\n",
    "    # Instead of manual loss implementation, Using Torch.nn.<LossFunction>\n",
    "    # loss = (y_pred - y).pow(2).sum()\n",
    "    loss = mse_loss(y_pred, y)\n",
    "    print(epoch, loss.item())\n",
    "    \n",
    "    # USE AUTOGRAD\n",
    "    # to compute backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    # After this call w1.grad and w2.grad will be Tensors holding the gradient\n",
    "    # of the loss with respect to w1 and w2 respectively.\n",
    "    loss.backward()\n",
    "    \n",
    "    # Using optimizer to step towards gradient descent and zeroing out grad\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-steam",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "residential-pasta",
   "metadata": {},
   "source": [
    "## Using pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "elementary-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "favorite-counter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0171806812286377\n",
      "1 1.090268611907959\n",
      "2 0.9514904022216797\n",
      "3 0.8523459434509277\n",
      "4 0.7531971335411072\n",
      "5 0.6300870180130005\n",
      "6 0.5352777242660522\n",
      "7 0.4524187743663788\n",
      "8 0.37616461515426636\n",
      "9 0.3109992444515228\n",
      "10 0.25395897030830383\n",
      "11 0.20431816577911377\n",
      "12 0.16136804223060608\n",
      "13 0.12471511960029602\n",
      "14 0.09422096610069275\n",
      "15 0.06942766159772873\n",
      "16 0.04972061514854431\n",
      "17 0.03440779820084572\n",
      "18 0.02287709154188633\n",
      "19 0.014634357765316963\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "# Load resnet18 pretrained model\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "data = torch.rand(1, 3, 64, 64)\n",
    "labels = torch.rand(1, 1000)\n",
    "\n",
    "# Instead of manual loss implementation, Using Torch.nn.<LossFunction>\n",
    "mse_loss = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "\n",
    "for epoch in range(20):\n",
    "    y_pred = model(data)\n",
    "    \n",
    "    # Compute loss\n",
    "    # Instead of manual loss implementation, Using Torch.nn.<LossFunction>\n",
    "    # loss = (y_pred - y).pow(2).sum()\n",
    "    loss = mse_loss(y_pred, labels)\n",
    "    print(epoch, loss.item())\n",
    "    \n",
    "    # USE AUTOGRAD\n",
    "    # to compute backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    # After this call w1.grad and w2.grad will be Tensors holding the gradient\n",
    "    # of the loss with respect to w1 and w2 respectively.\n",
    "    loss.backward()\n",
    "    \n",
    "    # Using optimizer to step towards gradient descent and zeroing out grad\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aggressive-leeds",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-wings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-discrimination",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
