{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "enabling-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived and modified from\n",
    "# Source: https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "import torch\n",
    "import numpy as np\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "first-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "x = np.random.rand(100, 1)\n",
    "y = 1 + 2 * x + .1 * np.random.randn(100, 1)\n",
    "\n",
    "# Shuffles the indices\n",
    "idx = np.arange(100)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# Uses first 80 random indices for train\n",
    "train_idx = idx[:80]\n",
    "# Uses the remaining indices for validation\n",
    "val_idx = idx[80:]\n",
    "\n",
    "# Generates train and validation sets\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_val, y_val = x[val_idx], y[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-intelligence",
   "metadata": {},
   "source": [
    "## Making Custom Dataset by inheriting Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "through-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inherits from Dataset Class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        \"\"\"\n",
    "        Normally you preprocess your data here\n",
    "        \n",
    "        it takes whatever arguments needed to build a list of tuples\n",
    "        There is no need to load the whold dataset in the constructor.\n",
    "        It is recommended to load them on demand (whenever __getitem__) is called.\n",
    "        \"\"\"\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Function which enables taking 1 sample from the dataset.\n",
    "        It allows the dataset to be indexed, so it can work like a list\n",
    "        Must return a tuple (features, label) corresponding to the requested data point.\n",
    "        \"\"\"\n",
    "        return (self.x[index], self.y[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Simply return the size of the whole dataset so whenever it is sampled, \n",
    "        its indexing is limited to the actual size.\n",
    "        \"\"\"\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "casual-arbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.7713]), tensor([2.4745]))\n",
      "(tensor([0.7713]), tensor([2.4745]))\n"
     ]
    }
   ],
   "source": [
    "# We do not send them to a device. So train_tensors are on CPU.\n",
    "# Because we don't want our whole training data to be loaded into GPU tensors\n",
    "# as it takes up space in our precious GPU's RAM.\n",
    "x_train_tensor = torch.from_numpy(x_train).float()  # no .to(device)\n",
    "y_train_tensor = torch.from_numpy(y_train).float()  # no .to(device)\n",
    "\n",
    "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
    "print(train_data[0])\n",
    "\n",
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-printing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "becoming-professor",
   "metadata": {},
   "source": [
    "## DataLoader --> mini-batch GD\n",
    "Above example can only do Batch Gradient Descent.  \n",
    "Continued from the CustomDataset and by using DataLoader, we can do mini-batch or SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "occupational-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "narrow-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "convinced-preservation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "welsh-teacher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader._SingleProcessDataLoaderIter"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "protected-correlation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.3253],\n",
       "         [0.3252],\n",
       "         [0.1409],\n",
       "         [0.2713],\n",
       "         [0.7751],\n",
       "         [0.7713],\n",
       "         [0.9507],\n",
       "         [0.9395],\n",
       "         [0.0254],\n",
       "         [0.1997]]),\n",
       " tensor([[1.8057],\n",
       "         [1.7291],\n",
       "         [1.1211],\n",
       "         [1.5105],\n",
       "         [2.4936],\n",
       "         [2.4745],\n",
       "         [2.8715],\n",
       "         [2.8890],\n",
       "         [1.0785],\n",
       "         [1.3651]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First set of mini-batch.\n",
    "# Returning a list containing two tensors, \n",
    "# One for features another for labels\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "novel-october",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From 03-Models.ipynb\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyLinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "def return_train_step_function(model, loss_function, optimizer):\n",
    "    # Build function that is to be returned and used in every epoch\n",
    "    def train_step(x, y):\n",
    "        model.train()\n",
    "        y_hat = model(x)\n",
    "        loss = loss_function(y, y_hat)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    \n",
    "    # returning a function\n",
    "    return train_step\n",
    "\n",
    "model = MyLinearModel().to(device)\n",
    "mse_loss = nn.MSELoss(reduction='mean')\n",
    "train_step_func = return_train_step_function(model=model, \n",
    "                                             loss_function=mse_loss,\n",
    "                                             optimizer=torch.optim.SGD(model.parameters(), lr=1e-1)\n",
    "                                            )\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aggressive-response",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[1.9698]])), ('linear.bias', tensor([1.0257]))])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "By using train_loader we've made, below can perform mini-batch GD\n",
    "\"\"\"\n",
    "\n",
    "for epoch in range(300):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # the dataset lives in the CPU, so do our mini-batches.\n",
    "        # so we need to send those mini-batches to the device \n",
    "        # where the model lives\n",
    "        \"\"\"\n",
    "        For bigger datasets, loading data sample by sample (into a CPU tensor) using Datasetâ€™s __get_item__ \n",
    "        and then sending all samples that belong to the same mini-batch at once to your GPU (device) \n",
    "        is the way to go in order to make the best use of your GPU's RAM.\n",
    "        \"\"\"\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "    \n",
    "        loss = train_step_func(x_batch, y_batch)  # returns loss.item() with mini-batch\n",
    "        losses.append(loss)\n",
    "\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-basis",
   "metadata": {},
   "source": [
    "Rather than splitting the dataset into train and validation like above (top cell), we can use `random_split()`. Then the splitted dataset can be fed into the `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "exempt-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fluid-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.from_numpy(x).float()\n",
    "y_tensor = torch.from_numpy(y).float()\n",
    "\n",
    "dataset = TensorDataset(x_tensor, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "whole-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(dataset, [80, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "casual-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=10)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-glasgow",
   "metadata": {},
   "source": [
    "### Evaluation with validation set\n",
    "Now our training loop can be changed like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "floral-coast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[1.9894]])), ('linear.bias', tensor([0.9916]))])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. By using train_loader we've made, below can perform mini-batch GD\n",
    "2. We use random_splitted and DataLoader'ed train and validation data\n",
    "\"\"\"\n",
    "losses = []\n",
    "val_losses =[]\n",
    "\n",
    "for epoch in range(300):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # the dataset lives in the CPU, so do our mini-batches.\n",
    "        # so we need to send those mini-batches to the device \n",
    "        # where the model lives\n",
    "        \"\"\"\n",
    "        For bigger datasets, loading data sample by sample (into a CPU tensor) using Datasetâ€™s __get_item__ \n",
    "        and then sending all samples that belong to the same mini-batch at once to your GPU (device) \n",
    "        is the way to go in order to make the best use of your GPU's RAM.\n",
    "        \"\"\"\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "    \n",
    "        loss = train_step_func(x_batch, y_batch)  # returns loss.item() with mini-batch\n",
    "        losses.append(loss)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            # to(device) for the same reason\n",
    "            x_val = x_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            y_hat = model(x_val)\n",
    "            val_loss = mse_loss(y_val, y_hat)\n",
    "            val_losses.append(val_loss.item())\n",
    "    \n",
    "\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-cruise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-vinyl",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "alike-battery",
   "metadata": {},
   "source": [
    "## Advanced Example\n",
    "## Custom Datasets, DataLoaders and Transforms\n",
    "Derived and modified from the\n",
    "source: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prescription-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-faculty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-motel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-method",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-steel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
